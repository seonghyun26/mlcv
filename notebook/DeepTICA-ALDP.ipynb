{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsFlHlZfV50f"
   },
   "source": [
    "# DeepLDA: Alanine dipeptide and aldol reaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCZRjkEkV50i"
   },
   "source": [
    "Reference paper: _Bonati, Rizzi and Parrinello, [JCPL](https://pubs.acs.org/doi/10.1021/acs.jpclett.0c00535) (2020)_ [[arXiv]](https://arxiv.org/abs/2002.06562).\n",
    "\n",
    "Prerequisite: DeepLDA tutorial.\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/luigibonati/mlcolvar/blob/main/docs/notebooks/examples/ex_DeepLDA.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdcS8p3kV50i"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pHcc18VOV50j",
    "outputId": "43bb4f5e-ac62-48ef-dbb8-78e4581fa90d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9dbdb791f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Colab setup\n",
    "import os\n",
    "\n",
    "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
    "    import subprocess\n",
    "    subprocess.run('wget https://raw.githubusercontent.com/luigibonati/mlcolvar/main/colab_setup.sh', shell=True)\n",
    "    cmd = subprocess.run('bash colab_setup.sh EXAMPLE', shell=True, stdout=subprocess.PIPE)\n",
    "    print(cmd.stdout.decode('utf-8'))\n",
    "\n",
    "# IMPORT PACKAGES\n",
    "import torch\n",
    "import lightning\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from mlcolvar.data import DictDataset\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBMYRkzeV50k"
   },
   "source": [
    "## Alanine dipeptide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCa99KRjV50l"
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opJSEsTmV50l"
   },
   "source": [
    "We use the alanine dipeptide simulation data from the [PLUMED-MASTERCLASS](https://github.com/luigibonati/masterclass-plumed/) repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tW3UVcMRV50l",
    "outputId": "83351325-54ac-4737-8d0e-c703c28346c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 dataframe shape:  (5001, 53)\n",
      "Class 1 dataframe shape:  (5001, 53)\n",
      "\n",
      " - Loaded dataframe (10002, 53): ['time', 'phi', 'psi', 'theta', 'xi', 'ene', 'd_2_5', 'd_2_6', 'd_2_7', 'd_2_9', 'd_2_11', 'd_2_15', 'd_2_16', 'd_2_17', 'd_2_19', 'd_5_6', 'd_5_7', 'd_5_9', 'd_5_11', 'd_5_15', 'd_5_16', 'd_5_17', 'd_5_19', 'd_6_7', 'd_6_9', 'd_6_11', 'd_6_15', 'd_6_16', 'd_6_17', 'd_6_19', 'd_7_9', 'd_7_11', 'd_7_15', 'd_7_16', 'd_7_17', 'd_7_19', 'd_9_11', 'd_9_15', 'd_9_16', 'd_9_17', 'd_9_19', 'd_11_15', 'd_11_16', 'd_11_17', 'd_11_19', 'd_15_16', 'd_15_17', 'd_15_19', 'd_16_17', 'd_16_19', 'd_17_19', 'walker', 'labels']\n",
      " - Descriptors (10002, 45): ['d_2_5', 'd_2_6', 'd_2_7', 'd_2_9', 'd_2_11', 'd_2_15', 'd_2_16', 'd_2_17', 'd_2_19', 'd_5_6', 'd_5_7', 'd_5_9', 'd_5_11', 'd_5_15', 'd_5_16', 'd_5_17', 'd_5_19', 'd_6_7', 'd_6_9', 'd_6_11', 'd_6_15', 'd_6_16', 'd_6_17', 'd_6_19', 'd_7_9', 'd_7_11', 'd_7_15', 'd_7_16', 'd_7_17', 'd_7_19', 'd_9_11', 'd_9_15', 'd_9_16', 'd_9_17', 'd_9_19', 'd_11_15', 'd_11_16', 'd_11_17', 'd_11_19', 'd_15_16', 'd_15_17', 'd_15_19', 'd_16_17', 'd_16_19', 'd_17_19']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shpark/.conda/envs/cmd/lib/python3.9/site-packages/mlcolvar/utils/timelagged.py:140: UserWarning: Monitoring the progress for the search of time-lagged configurations with a progress_bar requires `tqdm`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mlcolvar.utils.io import create_dataset_from_files, load_dataframe\n",
    "from mlcolvar.data import DictModule\n",
    "from mlcolvar.utils.timelagged import create_timelagged_dataset\n",
    "\n",
    "filenames = [ \"https://raw.githubusercontent.com/luigibonati/masterclass-plumed/main/1_DeepLDA/0_unbiased-sA/COLVAR\",\n",
    "              \"https://raw.githubusercontent.com/luigibonati/masterclass-plumed/main/1_DeepLDA/0_unbiased-sB/COLVAR\" ]\n",
    "n_states = len(filenames)\n",
    "\n",
    "dataset, df = create_dataset_from_files(\n",
    "    filenames,\n",
    "\tfilter_args={'regex':'d_' }, # select distances between heavy atoms\n",
    "\tcreate_labels=True,\n",
    "\treturn_dataframe=True,\n",
    ")\n",
    "\n",
    "\n",
    "X = df.filter(regex='d_').values\n",
    "dataset = create_timelagged_dataset(X,lag_time=1)\n",
    "datamodule = DictModule(dataset,lengths=[0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DictDataset( \"data\": [9998, 45], \"data_lag\": [9998, 45], \"weights\": [9998], \"weights_lag\": [9998] )\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n",
      "tensor([1., 1., 1.,  ..., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(dataset[\"weights\"])\n",
    "print(dataset[\"weights_lag\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3iiLe79V50m"
   },
   "source": [
    "### Train DeepTICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "U2DGWn2VV50m",
    "outputId": "f1a89a2d-984f-479a-f724-a5a0da7a92c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepTICA(\n",
       "  (loss_fn): ReduceEigenvaluesLoss()\n",
       "  (norm_in): Normalization(in_features=45, out_features=45, mode=mean_std)\n",
       "  (nn): FeedForward(\n",
       "    (nn): Sequential(\n",
       "      (0): Linear(in_features=45, out_features=30, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=30, out_features=30, bias=True)\n",
       "      (3): Tanh()\n",
       "      (4): Linear(in_features=30, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (tica): TICA(in_features=3, out_features=1)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlcolvar.cvs import DeepTICA\n",
    "\n",
    "n_components = 1\n",
    "nn_layers = [45, 30, 30, 3]\n",
    "options= {'nn': {'activation': 'tanh'} }\n",
    "\n",
    "model = DeepTICA(nn_layers, n_cvs=n_components, options=options)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CL_dataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_list,\n",
    "        data_augmented_list,\n",
    "        data_augmented_hard_list,\n",
    "        temperature_list,\n",
    "    ):\n",
    "        super(CL_dataset, self).__init__()\n",
    "        self.x = data_list\n",
    "        self.x_augmented = data_augmented_list\n",
    "        self.x_augmented_hard = data_augmented_hard_list\n",
    "        self.temperature = temperature_list\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\t    return self.x[index], self.x_augmented[index], self.x_augmented_hard[index], self.temperature[index]\n",
    " \n",
    "    def __len__(self):\n",
    "\t    return self.x.shape[0]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = torch.load(\"../../data/dataset/alanine/300.0/v3/cl-distance.pt\")\n",
    "custom_weights = torch.tensor([1], dtype=torch.float32).repeat(custom_dataset.x.shape[0])\n",
    "custom_weights_lag = torch.tensor([1], dtype=torch.float32).repeat(custom_dataset.x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = DictDataset({\n",
    "\t\"data\": custom_dataset.x,\n",
    "\t\"data_lag\": custom_dataset.x_augmented,\n",
    " \t\"weights\": custom_weights,\n",
    " \t\"weights_lag\": custom_weights_lag,\n",
    "})\n",
    "datamodule = DictModule(new_dataset,lengths=[0.8,0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DeepTICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xG2PwEXkV50m"
   },
   "source": [
    "Define trainer and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictModule(dataset -> DictDataset( \"data\": [400000, 45], \"data_lag\": [400000, 45], \"weights\": [400000], \"weights_lag\": [400000] ),\n",
       "\t\t     train_loader -> DictLoader(length=0.8, batch_size=0, shuffle=True),\n",
       "\t\t     valid_loader -> DictLoader(length=0.2, batch_size=0, shuffle=True))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLVRH1CpV50m",
    "outputId": "7c576571-d8aa-4a79-f4d8-004a4e22cffa"
   },
   "outputs": [],
   "source": [
    "import lightning\n",
    "\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from mlcolvar.utils.trainer import MetricsCallback\n",
    "\n",
    "# define callbacks\n",
    "metrics = MetricsCallback()\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"valid_loss\",\n",
    "    min_delta=1e-5,\n",
    "    patience=20\n",
    ")\n",
    "\n",
    "\n",
    "# define trainer\n",
    "trainer = lightning.Trainer(\n",
    "    callbacks=[metrics, early_stopping],\n",
    "\tmax_epochs=None,\n",
    " \tlogger=None,\n",
    "  \tenable_checkpointing=False\n",
    ")\n",
    "\n",
    "# fit\n",
    "trainer.fit( model, datamodule )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'deeptica-v4.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v1: original dataset\n",
    "\n",
    "v2: ??v\n",
    "\n",
    "v3: hard augmented as time lag\n",
    "\n",
    "v4: augmented as time lag, POSITIVE_SAMPLES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cmd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
